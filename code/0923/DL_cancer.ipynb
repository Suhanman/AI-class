{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1) 데이터 로드 (헤더 사용)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/breast_cancer.csv\")  # Colab이면 자신의 경로로 변경\n",
        "\n",
        "# 인덱스 열 제거\n",
        "if \"Unnamed: 0\" in df.columns:\n",
        "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "# 2) 특징/라벨 분리\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# 3) 학습/검증 분리 (계층적 분할)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 4) 모델 구성\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "lr = LogisticRegression(max_iter=1000, solver=\"liblinear\")  # 수렴 안정\n",
        "\n",
        "# 5) 학습\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# 6) 평가\n",
        "\n",
        "dt_y_pred = dt.predict(X_test)\n",
        "rf_y_pred = rf.predict(X_test)\n",
        "lr_y_pred = lr.predict(X_test)\n",
        "\n",
        "dt_acc = accuracy_score(y_test, dt_y_pred )\n",
        "rf_acc = accuracy_score(y_test, rf_y_pred)\n",
        "lr_acc = accuracy_score(y_test, lr_y_pred)\n",
        "\n",
        "print(\"=== Test Accuracy ===\")\n",
        "print(f\"Decision Tree : {dt_acc:.4f}\")\n",
        "print(f\"Random Forest : {rf_acc:.4f}\")\n",
        "print(f\"Logistic Reg. : {lr_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpbXkgawIzTL",
        "outputId": "a8c3a7c0-0141-4155-e702-bb9fec597941"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Test Accuracy ===\n",
            "Decision Tree : 0.9123\n",
            "Random Forest : 0.9561\n",
            "Logistic Reg. : 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 1) 데이터 로드\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/breast_cancer.csv\")\n",
        "\n",
        "# 인덱스 열 제거\n",
        "if \"Unnamed: 0\" in df.columns:\n",
        "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "# 2) 특징/라벨 분리\n",
        "X = df.drop(columns=[\"label\"])\n",
        "y = df[\"label\"]\n",
        "\n",
        "# ✅ numpy 변환\n",
        "X = X.values\n",
        "\n",
        "# ✅ 원핫 인코딩\n",
        "Y = pd.get_dummies(y).values\n",
        "\n",
        "# 3) 학습/검증 분리\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 4) 딥러닝 모델 구성\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(Y_train.shape[1], activation='softmax')  # 클래스 개수만큼 출력\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5) 학습\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=30,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 6) 평가\n",
        "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"\\n=== Test Accuracy ===\")\n",
        "print(f\"Deep Learning MLP : {acc:.4f}\")\n",
        "\n",
        "# 7) 분류 리포트 & 혼동 행렬\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "y_test_class = np.argmax(Y_test, axis=1)\n",
        "\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_test_class, y_pred_class))\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test_class, y_pred_class))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X3pFUXSMAh6",
        "outputId": "dd640e90-acc1-480a-80cd-f50d567dc617"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8557 - loss: 0.4469 - val_accuracy: 0.9451 - val_loss: 0.1878\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9281 - loss: 0.1813 - val_accuracy: 0.9670 - val_loss: 0.1122\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.0786 - val_accuracy: 0.9670 - val_loss: 0.0871\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9682 - loss: 0.0963 - val_accuracy: 0.9890 - val_loss: 0.0683\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9787 - loss: 0.0744 - val_accuracy: 0.9890 - val_loss: 0.0589\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0464 - val_accuracy: 0.9890 - val_loss: 0.0507\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9898 - loss: 0.0396 - val_accuracy: 0.9890 - val_loss: 0.0456\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0571 - val_accuracy: 1.0000 - val_loss: 0.0425\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0451 - val_accuracy: 0.9890 - val_loss: 0.0368\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0295 - val_accuracy: 0.9890 - val_loss: 0.0347\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.0453 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0404 - val_accuracy: 0.9890 - val_loss: 0.0306\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0426 - val_accuracy: 0.9890 - val_loss: 0.0300\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9912 - loss: 0.0249 - val_accuracy: 1.0000 - val_loss: 0.0285\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0220 - val_accuracy: 1.0000 - val_loss: 0.0292\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0193 - val_accuracy: 1.0000 - val_loss: 0.0254\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 0.0277\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0160 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0154 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0111 - val_accuracy: 0.9890 - val_loss: 0.0267\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0246\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.9890 - val_loss: 0.0242\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0095 - val_accuracy: 0.9890 - val_loss: 0.0228\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9890 - val_loss: 0.0236\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9890 - val_loss: 0.0233\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9890 - val_loss: 0.0244\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9890 - val_loss: 0.0229\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9890 - val_loss: 0.0219\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9890 - val_loss: 0.0229\n",
            "\n",
            "=== Test Accuracy ===\n",
            "Deep Learning MLP : 0.9561\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94        42\n",
            "           1       0.99      0.94      0.96        72\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.95      0.96      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "=== Confusion Matrix ===\n",
            "[[41  1]\n",
            " [ 4 68]]\n"
          ]
        }
      ]
    }
  ]
}