{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BhAGQdgAygL",
        "outputId": "e4deb693-8741-4dbb-bc08-dc011f067ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2942 - loss: 1.7395 - val_accuracy: 0.5179 - val_loss: 1.2311\n",
            "Epoch 2/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5281 - loss: 1.1852 - val_accuracy: 0.5395 - val_loss: 1.1559\n",
            "Epoch 3/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5455 - loss: 1.1078 - val_accuracy: 0.5408 - val_loss: 1.1206\n",
            "Epoch 4/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5616 - loss: 1.0537 - val_accuracy: 0.5497 - val_loss: 1.1035\n",
            "Epoch 5/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5537 - loss: 1.0575 - val_accuracy: 0.5561 - val_loss: 1.0996\n",
            "Epoch 6/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5837 - loss: 1.0337 - val_accuracy: 0.5395 - val_loss: 1.0988\n",
            "Epoch 7/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5672 - loss: 1.0037 - val_accuracy: 0.5587 - val_loss: 1.0918\n",
            "Epoch 8/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5661 - loss: 1.0132 - val_accuracy: 0.5651 - val_loss: 1.0837\n",
            "Epoch 9/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 0.9954 - val_accuracy: 0.5599 - val_loss: 1.0822\n",
            "Epoch 10/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5830 - loss: 0.9905 - val_accuracy: 0.5561 - val_loss: 1.0778\n",
            "Epoch 11/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 0.9795 - val_accuracy: 0.5548 - val_loss: 1.0799\n",
            "Epoch 12/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.9516 - val_accuracy: 0.5536 - val_loss: 1.0698\n",
            "Epoch 13/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 0.9642 - val_accuracy: 0.5421 - val_loss: 1.0752\n",
            "Epoch 14/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5953 - loss: 0.9623 - val_accuracy: 0.5587 - val_loss: 1.0729\n",
            "Epoch 15/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.9409 - val_accuracy: 0.5421 - val_loss: 1.0718\n",
            "Epoch 16/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6104 - loss: 0.9325 - val_accuracy: 0.5548 - val_loss: 1.0629\n",
            "Epoch 17/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 0.9380 - val_accuracy: 0.5510 - val_loss: 1.0657\n",
            "Epoch 18/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6208 - loss: 0.9096 - val_accuracy: 0.5459 - val_loss: 1.0588\n",
            "Epoch 19/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.9216 - val_accuracy: 0.5497 - val_loss: 1.0673\n",
            "Epoch 20/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.9109 - val_accuracy: 0.5651 - val_loss: 1.0599\n",
            "Epoch 21/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5972 - loss: 0.9146 - val_accuracy: 0.5612 - val_loss: 1.0617\n",
            "Epoch 22/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6259 - loss: 0.9197 - val_accuracy: 0.5485 - val_loss: 1.0658\n",
            "Epoch 23/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6216 - loss: 0.9154 - val_accuracy: 0.5638 - val_loss: 1.0677\n",
            "Epoch 24/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6316 - loss: 0.8919 - val_accuracy: 0.5561 - val_loss: 1.0753\n",
            "Epoch 25/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6263 - loss: 0.9006 - val_accuracy: 0.5536 - val_loss: 1.0629\n",
            "Epoch 26/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6419 - loss: 0.8791 - val_accuracy: 0.5472 - val_loss: 1.0609\n",
            "Epoch 27/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 0.8811 - val_accuracy: 0.5599 - val_loss: 1.0624\n",
            "Epoch 28/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6396 - loss: 0.8597 - val_accuracy: 0.5663 - val_loss: 1.0654\n",
            "Epoch 29/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: 0.8590 - val_accuracy: 0.5574 - val_loss: 1.0692\n",
            "Epoch 30/30\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6344 - loss: 0.8565 - val_accuracy: 0.5536 - val_loss: 1.0600\n",
            "\n",
            "=== Test Accuracy ===\n",
            "Deep Learning MLP : 0.5541\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.50      0.18      0.27        33\n",
            "           2       0.58      0.57      0.58       291\n",
            "           3       0.55      0.67      0.60       440\n",
            "           4       0.53      0.43      0.48       176\n",
            "           5       0.33      0.06      0.10        35\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.55       980\n",
            "   macro avg       0.36      0.27      0.29       980\n",
            "weighted avg       0.54      0.55      0.54       980\n",
            "\n",
            "=== Confusion Matrix ===\n",
            "[[  0   1   1   2   0   0   0]\n",
            " [  0   6  17  10   0   0   0]\n",
            " [  1   4 166 112   8   0   0]\n",
            " [  0   1  97 293  48   1   0]\n",
            " [  0   0   4  93  76   3   0]\n",
            " [  0   0   0  23  10   2   0]\n",
            " [  0   0   0   0   1   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# -----------------------------\n",
        "# 1) 데이터 준비\n",
        "# -----------------------------\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/winequality-white.csv\", sep=\";\").dropna()\n",
        "\n",
        "X = df.drop(columns=[\"quality\"])\n",
        "y = df[\"quality\"]\n",
        "\n",
        "# numpy 변환\n",
        "X = X.values\n",
        "\n",
        "# ✅ 원핫 인코딩\n",
        "Y = pd.get_dummies(y).values\n",
        "\n",
        "# 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# train/test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X_scaled, Y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 2) 딥러닝 모델 (분류)\n",
        "# -----------------------------\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(Y_train.shape[1], activation='softmax')  # 다중 클래스 분류\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# -----------------------------\n",
        "# 3) 학습\n",
        "# -----------------------------\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 4) 평가\n",
        "# -----------------------------\n",
        "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"\\n=== Test Accuracy ===\")\n",
        "print(f\"Deep Learning MLP : {acc:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5) 예측 → classification_report, confusion_matrix\n",
        "# -----------------------------\n",
        "# 예측 확률 -> 클래스 인덱스로 변환\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# 실제 y_test도 원핫 → 정수 인덱스로 변환\n",
        "y_test_class = np.argmax(Y_test, axis=1)\n",
        "\n",
        "# 리포트 출력\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_test_class, y_pred_class))\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test_class, y_pred_class))\n"
      ]
    }
  ]
}